2022-05-16 20:28:51 - utils.py[line:263] - INFO: distributed init (rank 0): env://
2022-05-16 20:28:51 - utils.py[line:269] - INFO: Start init
2022-05-16 20:28:51 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-05-16 20:28:51 - utils.py[line:279] - INFO: initialized host heming-ng1 as rank 0
single-machine distributed training is initialized.
2022-05-16 20:28:53 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None, 'is_moe': False}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 5000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 3, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './moe_stage1_checkpoints/3_0.06_2500_0.01_1e-5', 'restore_file': './moe_stage1_checkpoints/10_0.06_2500_0.01_1e-5/checkpoint.best_cider_1.2090.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'cider', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807, 'stats_path': None, 'max_valid_steps': None}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_moe_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, alternate_ffn_embed_dim=0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_moe_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='cider', bf16=False, block_wise=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_moe_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/caption_data/caption_stage1_train.tsv,../../dataset/caption_data/caption_val.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_moe_freq=1, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, drop_worst_after=2500, drop_worst_ratio=0.2, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_moe_freq=1, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":1,"max_len_b":16,"no_repeat_ngram_size":3}', eval_bleu=False, eval_cider=True, eval_cider_cached_tokens='../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, log_nvidia_smi=False, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=3, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=20, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, moe_eval_capacity_token_fraction=0.25, moe_expert_count=4, moe_expert_ffn_dim=0, moe_freq=1, moe_gate_loss_combine_method='average', moe_gate_loss_transform='none', moe_gate_loss_wt=1.0, moe_gating_use_fp32=True, moe_normalize_expert_grad='', moe_normalize_gate_prob_before_dropping=True, moe_second_expert_policy='all', moe_top1_expert=True, no_best_checkpoints=False, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_save_optimizer_state_on_training_finished=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_bins=1000, num_shards=1, num_workers=0, num_workers_valid=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='./moe_stage1_checkpoints/10_0.06_2500_0.01_1e-5/checkpoint.best_cider_1.2090.pt', s3_upload_path=None, sample_patch_num=196, save_dir='./moe_stage1_checkpoints/3_0.06_2500_0.01_1e-5', save_interval=1, save_interval_updates=5000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,4,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, symlink_best_and_last_checkpoints=False, sync_bn=False, task='caption', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_moe_pad_mask=True, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=5000, wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'caption', 'data': '../../dataset/caption_data/caption_stage1_train.tsv,../../dataset/caption_data/caption_val.tsv', 'selected_cols': '0,4,2', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 20, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_bleu': False, 'eval_cider': True, 'eval_args': '{"beam":1,"max_len_b":16,"no_repeat_ngram_size":3}', 'eval_print_samples': False, 'eval_cider_cached_tokens': '../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_moe_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.2, 'drop_worst_after': 2500, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None, 'moe_gate_loss_wt': 1.0, 'moe_gate_loss_combine_method': 'average', 'moe_gate_loss_transform': 'none'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05], 'block_wise': False}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-05-16 20:28:54 - ofa_task.py[line:103] - INFO: source dictionary: 59457 types
2022-05-16 20:28:54 - ofa_task.py[line:104] - INFO: target dictionary: 59457 types
2022-05-16 20:28:55 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-05-16 20:28:55 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:3 to store for rank: 0
2022-05-16 20:28:55 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:4 to store for rank: 0
2022-05-16 20:29:01 - train.py[line:108] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-05-16 20:29:01 - train.py[line:109] - INFO: task: CaptionTask
2022-05-16 20:29:01 - train.py[line:110] - INFO: model: OFAModel
2022-05-16 20:29:01 - train.py[line:111] - INFO: criterion: AdjustLabelSmoothedMOECrossEntropyCriterion
2022-05-16 20:29:01 - train.py[line:112] - INFO: num. shared model params: 125,606,216 (num. trained: 125,606,216)
2022-05-16 20:29:01 - train.py[line:119] - INFO: num. expert model params: 226676736 (num. trained: 226676736)
local datafile ../../dataset/caption_data/caption_val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_val.tsv slice_id 0 row count 5000 total row count 5000
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.0.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.1.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.2.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.3.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.4.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.5.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.0.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.1.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.2.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.3.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.4.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.5.moe_layer.gate.wg.bias
2022-05-16 20:29:02 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-05-16 20:29:02 - utils.py[line:779] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2022-05-16 20:29:02 - utils.py[line:781] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-05-16 20:29:02 - utils.py[line:787] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2022-05-16 20:29:02 - train.py[line:150] - INFO: training on 1 devices (GPUs/TPUs)
2022-05-16 20:29:02 - train.py[line:155] - INFO: max tokens per device = None and max sentences per device = 8
2022-05-16 20:29:02 - trainer.py[line:477] - INFO: Preparing to load checkpoint ./moe_stage1_checkpoints/10_0.06_2500_0.01_1e-5/checkpoint.best_cider_1.2090.pt
2022-05-16 20:29:08 - adam.py[line:70] - INFO: using FusedAdam
2022-05-16 20:29:08 - trainer.py[line:636] - INFO: Loaded checkpoint ./moe_stage1_checkpoints/10_0.06_2500_0.01_1e-5/checkpoint.best_cider_1.2090.pt (epoch 5 @ 0 updates)
2022-05-16 20:29:08 - trainer.py[line:658] - INFO: loading train data for epoch 1
local datafile ../../dataset/caption_data/caption_stage1_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_stage1_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train.tsv slice_id 0 row count 566747 total row count 566747
slice_id 0 seek offset 0
Total steps 53133, warmup steps 3187, warmup_factor 0.00031377470975839345
2022-05-16 20:29:35 - trainer.py[line:722] - INFO: begin training epoch 1
2022-05-16 20:29:35 - train.py[line:303] - INFO: Start iterating over samples
2022-05-16 20:30:08 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 17711 loss=4.054, loss_v1=0, loss_v2=0, nll_loss=2.015, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.880175, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.069, expert1_balance_top=34.646, expert1_balance_bottom=19.483, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.04, wps=156.9, ups=0.41, wpb=382, bsz=32, num_updates=10, lr=3.13775e-08, gnorm=4.682, loss_scale=128, train_wall=32, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=66
2022-05-16 20:30:28 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 17711 loss=4.061, loss_v1=0, loss_v2=0, nll_loss=2.025, ntokens=382.4, nsentences=32, sample_size=382.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.875372, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.065, expert1_balance_top=35.169, expert1_balance_bottom=19.293, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.07, wps=188.1, ups=0.49, wpb=382.4, bsz=32, num_updates=20, lr=6.27549e-08, gnorm=4.757, loss_scale=128, train_wall=20, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=87
2022-05-16 20:30:51 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 17711 loss=4.204, loss_v1=0, loss_v2=0, nll_loss=2.171, ntokens=374.3, nsentences=32, sample_size=374.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.888759, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.075, expert1_balance_top=34.204, expert1_balance_bottom=19.679, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.5, wps=165.6, ups=0.44, wpb=374.3, bsz=32, num_updates=30, lr=9.41324e-08, gnorm=5.169, loss_scale=128, train_wall=18, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=109
2022-05-16 20:31:03 - trainer.py[line:945] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-16 20:31:29 - progress_bar.py[line:272] - INFO: epoch 001:     41 / 17711 loss=4.106, loss_v1=0, loss_v2=0, nll_loss=2.069, ntokens=379.4, nsentences=32, sample_size=379.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.882973, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.069, expert1_balance_top=34.602, expert1_balance_bottom=19.571, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.2, wps=98.8, ups=0.26, wpb=379.4, bsz=32, num_updates=40, lr=1.2551e-07, gnorm=5.111, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=148
2022-05-16 20:32:11 - progress_bar.py[line:272] - INFO: epoch 001:     51 / 17711 loss=4.114, loss_v1=0, loss_v2=0, nll_loss=2.075, ntokens=371, nsentences=32, sample_size=371, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.884142, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.071, expert1_balance_top=34.551, expert1_balance_bottom=19.338, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.21, wps=88, ups=0.24, wpb=371, bsz=32, num_updates=50, lr=1.56887e-07, gnorm=4.898, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=190
2022-05-16 20:32:52 - progress_bar.py[line:272] - INFO: epoch 001:     61 / 17711 loss=3.998, loss_v1=0, loss_v2=0, nll_loss=1.94, ntokens=392.4, nsentences=32, sample_size=392.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.890138, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.073, expert1_balance_top=34.468, expert1_balance_bottom=19.481, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.84, wps=96.4, ups=0.25, wpb=392.4, bsz=32, num_updates=60, lr=1.88265e-07, gnorm=5.576, loss_scale=64, train_wall=20, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=230
2022-05-16 20:33:34 - progress_bar.py[line:272] - INFO: epoch 001:     71 / 17711 loss=4.251, loss_v1=0, loss_v2=0, nll_loss=2.231, ntokens=387.2, nsentences=32, sample_size=387.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.881152, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.069, expert1_balance_top=35.084, expert1_balance_bottom=19.309, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.7, wps=92.7, ups=0.24, wpb=387.2, bsz=32, num_updates=70, lr=2.19642e-07, gnorm=4.784, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=272
2022-05-16 20:34:15 - progress_bar.py[line:272] - INFO: epoch 001:     81 / 17711 loss=4.192, loss_v1=0, loss_v2=0, nll_loss=2.157, ntokens=377.6, nsentences=32, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.890025, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.074, expert1_balance_top=34.418, expert1_balance_bottom=19.538, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.46, wps=91.6, ups=0.24, wpb=377.6, bsz=32, num_updates=80, lr=2.5102e-07, gnorm=5.344, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=313
2022-05-16 20:34:58 - progress_bar.py[line:272] - INFO: epoch 001:     91 / 17711 loss=4.121, loss_v1=0, loss_v2=0, nll_loss=2.093, ntokens=374.9, nsentences=32, sample_size=374.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.875061, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.066, expert1_balance_top=35.254, expert1_balance_bottom=19.158, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.27, wps=87.9, ups=0.23, wpb=374.9, bsz=32, num_updates=90, lr=2.82397e-07, gnorm=4.589, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=356
2022-05-16 20:35:42 - progress_bar.py[line:272] - INFO: epoch 001:    101 / 17711 loss=4.035, loss_v1=0, loss_v2=0, nll_loss=1.984, ntokens=386.9, nsentences=32, sample_size=386.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.887941, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.073, expert1_balance_top=34.274, expert1_balance_bottom=19.529, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.96, wps=88, ups=0.23, wpb=386.9, bsz=32, num_updates=100, lr=3.13775e-07, gnorm=4.63, loss_scale=64, train_wall=23, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=400
2022-05-16 20:36:25 - progress_bar.py[line:272] - INFO: epoch 001:    111 / 17711 loss=4.127, loss_v1=0, loss_v2=0, nll_loss=2.086, ntokens=382.3, nsentences=32, sample_size=382.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889509, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.075, expert1_balance_top=34.177, expert1_balance_bottom=19.441, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.25, wps=88.9, ups=0.23, wpb=382.3, bsz=32, num_updates=110, lr=3.45152e-07, gnorm=5.019, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=443
2022-05-16 20:37:07 - progress_bar.py[line:272] - INFO: epoch 001:    121 / 17711 loss=4.184, loss_v1=0, loss_v2=0, nll_loss=2.159, ntokens=392.3, nsentences=32, sample_size=392.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.881108, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.07, expert1_balance_top=34.47, expert1_balance_bottom=19.64, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.47, wps=92.3, ups=0.24, wpb=392.3, bsz=32, num_updates=120, lr=3.7653e-07, gnorm=5.348, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=486
2022-05-16 20:37:50 - progress_bar.py[line:272] - INFO: epoch 001:    131 / 17711 loss=4.145, loss_v1=0, loss_v2=0, nll_loss=2.128, ntokens=395.6, nsentences=32, sample_size=395.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.871357, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.065, expert1_balance_top=35.276, expert1_balance_bottom=19.222, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.37, wps=92.6, ups=0.23, wpb=395.6, bsz=32, num_updates=130, lr=4.07907e-07, gnorm=4.525, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=528
2022-05-16 20:38:33 - progress_bar.py[line:272] - INFO: epoch 001:    141 / 17711 loss=4.035, loss_v1=0, loss_v2=0, nll_loss=1.987, ntokens=375.3, nsentences=32, sample_size=375.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.891903, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.075, expert1_balance_top=34.183, expert1_balance_bottom=19.707, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.96, wps=87.9, ups=0.23, wpb=375.3, bsz=32, num_updates=140, lr=4.39285e-07, gnorm=5.216, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=571
2022-05-16 20:39:15 - progress_bar.py[line:272] - INFO: epoch 001:    151 / 17711 loss=4.027, loss_v1=0, loss_v2=0, nll_loss=1.984, ntokens=376.6, nsentences=32, sample_size=376.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.888243, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.075, expert1_balance_top=34.397, expert1_balance_bottom=19.485, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.96, wps=89.7, ups=0.24, wpb=376.6, bsz=32, num_updates=150, lr=4.70662e-07, gnorm=4.567, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=613
2022-05-16 20:39:56 - progress_bar.py[line:272] - INFO: epoch 001:    161 / 17711 loss=4.015, loss_v1=0, loss_v2=0, nll_loss=1.966, ntokens=376.2, nsentences=32, sample_size=376.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.895054, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.08, expert1_balance_top=33.885, expert1_balance_bottom=19.67, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.91, wps=90.7, ups=0.24, wpb=376.2, bsz=32, num_updates=160, lr=5.0204e-07, gnorm=4.857, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=654
2022-05-16 20:40:39 - progress_bar.py[line:272] - INFO: epoch 001:    171 / 17711 loss=4.136, loss_v1=0, loss_v2=0, nll_loss=2.115, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.884787, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.073, expert1_balance_top=34.598, expert1_balance_bottom=19.392, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.33, wps=88, ups=0.23, wpb=382, bsz=32, num_updates=170, lr=5.33417e-07, gnorm=4.658, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=698
2022-05-16 20:41:20 - progress_bar.py[line:272] - INFO: epoch 001:    181 / 17711 loss=4.051, loss_v1=0, loss_v2=0, nll_loss=2.015, ntokens=379.5, nsentences=32, sample_size=379.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889512, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.077, expert1_balance_top=34.262, expert1_balance_bottom=19.486, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.04, wps=93.4, ups=0.25, wpb=379.5, bsz=32, num_updates=180, lr=5.64794e-07, gnorm=5.046, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=738
2022-05-16 20:42:04 - progress_bar.py[line:272] - INFO: epoch 001:    191 / 17711 loss=3.993, loss_v1=0, loss_v2=0, nll_loss=1.954, ntokens=379.8, nsentences=32, sample_size=379.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.887566, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.076, expert1_balance_top=34.785, expert1_balance_bottom=19.263, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.87, wps=87.2, ups=0.23, wpb=379.8, bsz=32, num_updates=190, lr=5.96172e-07, gnorm=4.765, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=782
2022-05-16 20:42:48 - progress_bar.py[line:272] - INFO: epoch 001:    201 / 17711 loss=4.05, loss_v1=0, loss_v2=0, nll_loss=2.017, ntokens=378.3, nsentences=32, sample_size=378.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.892733, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.076, expert1_balance_top=34.462, expert1_balance_bottom=19.471, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.05, wps=85.6, ups=0.23, wpb=378.3, bsz=32, num_updates=200, lr=6.27549e-07, gnorm=4.695, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=826
2022-05-16 20:43:30 - progress_bar.py[line:272] - INFO: epoch 001:    211 / 17711 loss=4.057, loss_v1=0, loss_v2=0, nll_loss=2.027, ntokens=384.2, nsentences=32, sample_size=384.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.892409, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.08, expert1_balance_top=33.981, expert1_balance_bottom=19.687, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.07, wps=90.6, ups=0.24, wpb=384.2, bsz=32, num_updates=210, lr=6.58927e-07, gnorm=5.042, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=869
2022-05-16 20:44:14 - progress_bar.py[line:272] - INFO: epoch 001:    221 / 17711 loss=4.04, loss_v1=0, loss_v2=0, nll_loss=2.014, ntokens=376.2, nsentences=32, sample_size=376.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.890382, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.077, expert1_balance_top=34.39, expert1_balance_bottom=19.452, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.04, wps=85.4, ups=0.23, wpb=376.2, bsz=32, num_updates=220, lr=6.90304e-07, gnorm=4.314, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=913
2022-05-16 20:44:57 - progress_bar.py[line:272] - INFO: epoch 001:    231 / 17711 loss=3.962, loss_v1=0, loss_v2=0, nll_loss=1.934, ntokens=384.1, nsentences=32, sample_size=384.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.883125, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.073, expert1_balance_top=35.061, expert1_balance_bottom=19.362, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.82, wps=90.3, ups=0.24, wpb=384.1, bsz=32, num_updates=230, lr=7.21682e-07, gnorm=4.286, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=955
2022-05-16 20:45:41 - progress_bar.py[line:272] - INFO: epoch 001:    241 / 17711 loss=3.851, loss_v1=0, loss_v2=0, nll_loss=1.817, ntokens=384.8, nsentences=32, sample_size=384.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.879569, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.072, expert1_balance_top=35.417, expert1_balance_bottom=19.065, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.52, wps=86.6, ups=0.23, wpb=384.8, bsz=32, num_updates=240, lr=7.53059e-07, gnorm=3.799, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1000
2022-05-16 20:46:24 - progress_bar.py[line:272] - INFO: epoch 001:    251 / 17711 loss=4.013, loss_v1=0, loss_v2=0, nll_loss=1.987, ntokens=383.6, nsentences=32, sample_size=383.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.887353, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.078, expert1_balance_top=34.447, expert1_balance_bottom=19.374, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.97, wps=89.9, ups=0.23, wpb=383.6, bsz=32, num_updates=250, lr=7.84437e-07, gnorm=4.161, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1042
2022-05-16 20:47:06 - progress_bar.py[line:272] - INFO: epoch 001:    261 / 17711 loss=4.041, loss_v1=0, loss_v2=0, nll_loss=2.029, ntokens=384.6, nsentences=32, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.881398, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.075, expert1_balance_top=35.073, expert1_balance_bottom=19.229, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.08, wps=90.7, ups=0.24, wpb=384.6, bsz=32, num_updates=260, lr=8.15814e-07, gnorm=3.952, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1085
2022-05-16 20:47:49 - progress_bar.py[line:272] - INFO: epoch 001:    271 / 17711 loss=4.169, loss_v1=0, loss_v2=0, nll_loss=2.161, ntokens=374.9, nsentences=32, sample_size=374.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889062, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.08, expert1_balance_top=34.239, expert1_balance_bottom=19.47, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.47, wps=88.4, ups=0.24, wpb=374.9, bsz=32, num_updates=270, lr=8.47192e-07, gnorm=4.574, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1127
2022-05-16 20:48:31 - progress_bar.py[line:272] - INFO: epoch 001:    281 / 17711 loss=3.986, loss_v1=0, loss_v2=0, nll_loss=1.972, ntokens=383.7, nsentences=32, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.880552, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.076, expert1_balance_top=34.958, expert1_balance_bottom=19.36, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.92, wps=90.3, ups=0.24, wpb=383.7, bsz=32, num_updates=280, lr=8.78569e-07, gnorm=4.196, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1170
2022-05-16 20:49:14 - progress_bar.py[line:272] - INFO: epoch 001:    291 / 17711 loss=4.079, loss_v1=0, loss_v2=0, nll_loss=2.053, ntokens=367.9, nsentences=32, sample_size=367.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.902898, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=33.927, expert1_balance_bottom=19.579, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.15, wps=85.8, ups=0.23, wpb=367.9, bsz=32, num_updates=290, lr=9.09947e-07, gnorm=4.718, loss_scale=64, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1212
2022-05-16 20:49:57 - progress_bar.py[line:272] - INFO: epoch 001:    301 / 17711 loss=4.092, loss_v1=0, loss_v2=0, nll_loss=2.114, ntokens=389.1, nsentences=32, sample_size=389.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.859098, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.064, expert1_balance_top=36.198, expert1_balance_bottom=18.977, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.33, wps=90.3, ups=0.23, wpb=389.1, bsz=32, num_updates=300, lr=9.41324e-07, gnorm=4.144, loss_scale=64, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1256
2022-05-16 20:50:23 - trainer.py[line:945] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-05-16 20:50:44 - progress_bar.py[line:272] - INFO: epoch 001:    312 / 17711 loss=4.044, loss_v1=0, loss_v2=0, nll_loss=2.038, ntokens=384.7, nsentences=32, sample_size=384.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.882651, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.08, expert1_balance_top=34.932, expert1_balance_bottom=19.308, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.11, wps=81.8, ups=0.21, wpb=384.7, bsz=32, num_updates=310, lr=9.72702e-07, gnorm=4.181, loss_scale=32, train_wall=23, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1303
2022-05-16 20:51:27 - progress_bar.py[line:272] - INFO: epoch 001:    322 / 17711 loss=3.96, loss_v1=0, loss_v2=0, nll_loss=1.948, ntokens=388.7, nsentences=32, sample_size=388.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.875767, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.074, expert1_balance_top=35.592, expert1_balance_bottom=19.062, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.86, wps=91.9, ups=0.24, wpb=388.7, bsz=32, num_updates=320, lr=1.00408e-06, gnorm=3.967, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1345
2022-05-16 20:52:08 - progress_bar.py[line:272] - INFO: epoch 001:    332 / 17711 loss=4.063, loss_v1=0, loss_v2=0, nll_loss=2.069, ntokens=378.8, nsentences=32, sample_size=378.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.875707, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.074, expert1_balance_top=35.377, expert1_balance_bottom=19.227, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.2, wps=90.4, ups=0.24, wpb=378.8, bsz=32, num_updates=330, lr=1.03546e-06, gnorm=4.218, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1387
2022-05-16 20:52:52 - progress_bar.py[line:272] - INFO: epoch 001:    342 / 17711 loss=4.018, loss_v1=0, loss_v2=0, nll_loss=1.999, ntokens=386.1, nsentences=32, sample_size=386.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.891358, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.083, expert1_balance_top=34.428, expert1_balance_bottom=19.422, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4, wps=89.3, ups=0.23, wpb=386.1, bsz=32, num_updates=340, lr=1.06683e-06, gnorm=4.064, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1430
2022-05-16 20:53:34 - progress_bar.py[line:272] - INFO: epoch 001:    352 / 17711 loss=3.951, loss_v1=0, loss_v2=0, nll_loss=1.922, ntokens=381, nsentences=32, sample_size=381, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.898097, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.085, expert1_balance_top=34.446, expert1_balance_bottom=19.56, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.79, wps=88.9, ups=0.23, wpb=381, bsz=32, num_updates=350, lr=1.09821e-06, gnorm=4.128, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1473
2022-05-16 20:54:18 - progress_bar.py[line:272] - INFO: epoch 001:    362 / 17711 loss=3.901, loss_v1=0, loss_v2=0, nll_loss=1.876, ntokens=382.5, nsentences=32, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889341, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.082, expert1_balance_top=35.23, expert1_balance_bottom=19.215, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.67, wps=88.4, ups=0.23, wpb=382.5, bsz=32, num_updates=360, lr=1.12959e-06, gnorm=3.455, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1516
2022-05-16 20:55:01 - progress_bar.py[line:272] - INFO: epoch 001:    372 / 17711 loss=3.964, loss_v1=0, loss_v2=0, nll_loss=1.947, ntokens=377.7, nsentences=32, sample_size=377.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.888906, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.082, expert1_balance_top=35.094, expert1_balance_bottom=19.295, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.86, wps=88.3, ups=0.23, wpb=377.7, bsz=32, num_updates=370, lr=1.16097e-06, gnorm=3.618, loss_scale=32, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1559
2022-05-16 20:55:43 - progress_bar.py[line:272] - INFO: epoch 001:    382 / 17711 loss=3.928, loss_v1=0, loss_v2=0, nll_loss=1.896, ntokens=379.3, nsentences=32, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.895078, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.086, expert1_balance_top=34.626, expert1_balance_bottom=19.21, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.72, wps=89.2, ups=0.24, wpb=379.3, bsz=32, num_updates=380, lr=1.19234e-06, gnorm=3.802, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1601
2022-05-16 20:56:25 - progress_bar.py[line:272] - INFO: epoch 001:    392 / 17711 loss=3.922, loss_v1=0, loss_v2=0, nll_loss=1.908, ntokens=385, nsentences=32, sample_size=385, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.879608, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.078, expert1_balance_top=35.356, expert1_balance_bottom=19.196, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.75, wps=91.1, ups=0.24, wpb=385, bsz=32, num_updates=390, lr=1.22372e-06, gnorm=3.585, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1644
2022-05-16 20:57:07 - progress_bar.py[line:272] - INFO: epoch 001:    402 / 17711 loss=4.054, loss_v1=0, loss_v2=0, nll_loss=2.057, ntokens=383.5, nsentences=32, sample_size=383.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.87502, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.077, expert1_balance_top=35.672, expert1_balance_bottom=19.048, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.16, wps=91.1, ups=0.24, wpb=383.5, bsz=32, num_updates=400, lr=1.2551e-06, gnorm=3.976, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1686
2022-05-16 20:57:50 - progress_bar.py[line:272] - INFO: epoch 001:    412 / 17711 loss=3.908, loss_v1=0, loss_v2=0, nll_loss=1.881, ntokens=383.4, nsentences=32, sample_size=383.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.891868, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=34.68, expert1_balance_bottom=19.316, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.68, wps=89.1, ups=0.23, wpb=383.4, bsz=32, num_updates=410, lr=1.28648e-06, gnorm=3.992, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1729
2022-05-16 20:58:34 - progress_bar.py[line:272] - INFO: epoch 001:    422 / 17711 loss=3.954, loss_v1=0, loss_v2=0, nll_loss=1.927, ntokens=377.8, nsentences=32, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.894996, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.089, expert1_balance_top=34.261, expert1_balance_bottom=19.529, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.8, wps=86.7, ups=0.23, wpb=377.8, bsz=32, num_updates=420, lr=1.31785e-06, gnorm=3.831, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1772
2022-05-16 20:59:17 - progress_bar.py[line:272] - INFO: epoch 001:    432 / 17711 loss=3.895, loss_v1=0, loss_v2=0, nll_loss=1.862, ntokens=381.2, nsentences=32, sample_size=381.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.893287, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=34.645, expert1_balance_bottom=19.587, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.64, wps=89, ups=0.23, wpb=381.2, bsz=32, num_updates=430, lr=1.34923e-06, gnorm=3.658, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1815
2022-05-16 21:00:00 - progress_bar.py[line:272] - INFO: epoch 001:    442 / 17711 loss=3.977, loss_v1=0, loss_v2=0, nll_loss=1.945, ntokens=381.6, nsentences=32, sample_size=381.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.901334, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.093, expert1_balance_top=33.874, expert1_balance_bottom=19.525, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.85, wps=88.8, ups=0.23, wpb=381.6, bsz=32, num_updates=440, lr=1.38061e-06, gnorm=3.709, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1858
2022-05-16 21:00:42 - progress_bar.py[line:272] - INFO: epoch 001:    452 / 17711 loss=3.959, loss_v1=0, loss_v2=0, nll_loss=1.932, ntokens=377.2, nsentences=32, sample_size=377.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.893359, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.089, expert1_balance_top=34.421, expert1_balance_bottom=19.369, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.82, wps=90.2, ups=0.24, wpb=377.2, bsz=32, num_updates=450, lr=1.41199e-06, gnorm=3.668, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1900
2022-05-16 21:01:23 - progress_bar.py[line:272] - INFO: epoch 001:    462 / 17711 loss=3.89, loss_v1=0, loss_v2=0, nll_loss=1.858, ntokens=389.3, nsentences=32, sample_size=389.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.893647, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.086, expert1_balance_top=34.628, expert1_balance_bottom=19.477, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.62, wps=93.9, ups=0.24, wpb=389.3, bsz=32, num_updates=460, lr=1.44336e-06, gnorm=3.644, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1941
2022-05-16 21:02:05 - progress_bar.py[line:272] - INFO: epoch 001:    472 / 17711 loss=4.008, loss_v1=0, loss_v2=0, nll_loss=1.977, ntokens=384.6, nsentences=32, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.905253, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.097, expert1_balance_top=34.02, expert1_balance_bottom=19.596, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.94, wps=91.3, ups=0.24, wpb=384.6, bsz=32, num_updates=470, lr=1.47474e-06, gnorm=3.693, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=1983
2022-05-16 21:02:47 - progress_bar.py[line:272] - INFO: epoch 001:    482 / 17711 loss=3.892, loss_v1=0, loss_v2=0, nll_loss=1.859, ntokens=384.4, nsentences=32, sample_size=384.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.890661, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=34.877, expert1_balance_bottom=19.261, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.63, wps=91.2, ups=0.24, wpb=384.4, bsz=32, num_updates=480, lr=1.50612e-06, gnorm=3.814, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2026
2022-05-16 21:03:29 - progress_bar.py[line:272] - INFO: epoch 001:    492 / 17711 loss=3.99, loss_v1=0, loss_v2=0, nll_loss=1.992, ntokens=398.2, nsentences=32, sample_size=398.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.867919, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.073, expert1_balance_top=36.32, expert1_balance_bottom=18.861, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.98, wps=94.3, ups=0.24, wpb=398.2, bsz=32, num_updates=490, lr=1.5375e-06, gnorm=3.577, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2068
2022-05-16 21:04:11 - progress_bar.py[line:272] - INFO: epoch 001:    502 / 17711 loss=3.948, loss_v1=0, loss_v2=0, nll_loss=1.931, ntokens=381.1, nsentences=32, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.883683, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.082, expert1_balance_top=35.758, expert1_balance_bottom=19.106, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.81, wps=91.9, ups=0.24, wpb=381.1, bsz=32, num_updates=500, lr=1.56887e-06, gnorm=3.525, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2109
2022-05-16 21:04:54 - progress_bar.py[line:272] - INFO: epoch 001:    512 / 17711 loss=3.986, loss_v1=0, loss_v2=0, nll_loss=1.966, ntokens=380.4, nsentences=32, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.891248, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.09, expert1_balance_top=34.533, expert1_balance_bottom=19.343, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.91, wps=88.9, ups=0.23, wpb=380.4, bsz=32, num_updates=510, lr=1.60025e-06, gnorm=3.77, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2152
2022-05-16 21:05:37 - progress_bar.py[line:272] - INFO: epoch 001:    522 / 17711 loss=4.018, loss_v1=0, loss_v2=0, nll_loss=2.015, ntokens=375.7, nsentences=32, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.877364, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.081, expert1_balance_top=35.329, expert1_balance_bottom=19.202, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.04, wps=87.4, ups=0.23, wpb=375.7, bsz=32, num_updates=520, lr=1.63163e-06, gnorm=4.007, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2195
2022-05-16 21:06:20 - progress_bar.py[line:272] - INFO: epoch 001:    532 / 17711 loss=3.963, loss_v1=0, loss_v2=0, nll_loss=1.942, ntokens=380.5, nsentences=32, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.892316, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.09, expert1_balance_top=34.543, expert1_balance_bottom=19.365, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.84, wps=88.7, ups=0.23, wpb=380.5, bsz=32, num_updates=530, lr=1.66301e-06, gnorm=3.473, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2238
2022-05-16 21:07:01 - progress_bar.py[line:272] - INFO: epoch 001:    542 / 17711 loss=3.934, loss_v1=0, loss_v2=0, nll_loss=1.91, ntokens=383.4, nsentences=32, sample_size=383.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889349, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.089, expert1_balance_top=34.764, expert1_balance_bottom=19.544, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.76, wps=92.6, ups=0.24, wpb=383.4, bsz=32, num_updates=540, lr=1.69438e-06, gnorm=3.983, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2279
2022-05-16 21:07:43 - progress_bar.py[line:272] - INFO: epoch 001:    552 / 17711 loss=4.009, loss_v1=0, loss_v2=0, nll_loss=1.991, ntokens=379.5, nsentences=32, sample_size=379.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889959, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=34.759, expert1_balance_bottom=19.314, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.98, wps=89.7, ups=0.24, wpb=379.5, bsz=32, num_updates=550, lr=1.72576e-06, gnorm=3.328, loss_scale=32, train_wall=20, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2322
2022-05-16 21:08:27 - progress_bar.py[line:272] - INFO: epoch 001:    562 / 17711 loss=3.94, loss_v1=0, loss_v2=0, nll_loss=1.918, ntokens=380.5, nsentences=32, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.885297, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.086, expert1_balance_top=35.249, expert1_balance_bottom=19.266, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.78, wps=88, ups=0.23, wpb=380.5, bsz=32, num_updates=560, lr=1.75714e-06, gnorm=3.733, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2365
2022-05-16 21:09:09 - progress_bar.py[line:272] - INFO: epoch 001:    572 / 17711 loss=3.941, loss_v1=0, loss_v2=0, nll_loss=1.912, ntokens=379.5, nsentences=32, sample_size=379.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.89252, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.091, expert1_balance_top=34.783, expert1_balance_bottom=19.369, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.76, wps=90.3, ups=0.24, wpb=379.5, bsz=32, num_updates=570, lr=1.78852e-06, gnorm=3.559, loss_scale=32, train_wall=20, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2407
2022-05-16 21:09:52 - progress_bar.py[line:272] - INFO: epoch 001:    582 / 17711 loss=3.954, loss_v1=0, loss_v2=0, nll_loss=1.935, ntokens=380.2, nsentences=32, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.886117, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.085, expert1_balance_top=35.005, expert1_balance_bottom=19.408, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.82, wps=87.2, ups=0.23, wpb=380.2, bsz=32, num_updates=580, lr=1.81989e-06, gnorm=3.502, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2451
2022-05-16 21:10:35 - progress_bar.py[line:272] - INFO: epoch 001:    592 / 17711 loss=3.852, loss_v1=0, loss_v2=0, nll_loss=1.808, ntokens=381.7, nsentences=32, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.89505, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.091, expert1_balance_top=35.078, expert1_balance_bottom=19.183, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.5, wps=89, ups=0.23, wpb=381.7, bsz=32, num_updates=590, lr=1.85127e-06, gnorm=3.861, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2493
2022-05-16 21:11:17 - progress_bar.py[line:272] - INFO: epoch 001:    602 / 17711 loss=4.009, loss_v1=0, loss_v2=0, nll_loss=1.971, ntokens=376.8, nsentences=32, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.90506, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.101, expert1_balance_top=33.695, expert1_balance_bottom=19.539, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.92, wps=91, ups=0.24, wpb=376.8, bsz=32, num_updates=600, lr=1.88265e-06, gnorm=3.767, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2535
2022-05-16 21:11:59 - progress_bar.py[line:272] - INFO: epoch 001:    612 / 17711 loss=3.992, loss_v1=0, loss_v2=0, nll_loss=1.972, ntokens=388.9, nsentences=32, sample_size=388.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.88408, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.084, expert1_balance_top=35.336, expert1_balance_bottom=19.162, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.92, wps=90.5, ups=0.23, wpb=388.9, bsz=32, num_updates=610, lr=1.91403e-06, gnorm=3.388, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2578
2022-05-16 21:12:42 - progress_bar.py[line:272] - INFO: epoch 001:    622 / 17711 loss=3.867, loss_v1=0, loss_v2=0, nll_loss=1.819, ntokens=385.5, nsentences=32, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.897104, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.093, expert1_balance_top=34.375, expert1_balance_bottom=19.569, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.53, wps=90, ups=0.23, wpb=385.5, bsz=32, num_updates=620, lr=1.9454e-06, gnorm=3.486, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2621
2022-05-16 21:13:25 - progress_bar.py[line:272] - INFO: epoch 001:    632 / 17711 loss=3.906, loss_v1=0, loss_v2=0, nll_loss=1.874, ntokens=381.9, nsentences=32, sample_size=381.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.8873, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=34.825, expert1_balance_bottom=19.425, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.67, wps=90, ups=0.24, wpb=381.9, bsz=32, num_updates=630, lr=1.97678e-06, gnorm=3.619, loss_scale=32, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2663
2022-05-16 21:14:08 - progress_bar.py[line:272] - INFO: epoch 001:    642 / 17711 loss=3.945, loss_v1=0, loss_v2=0, nll_loss=1.915, ntokens=385.2, nsentences=32, sample_size=385.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.892709, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.09, expert1_balance_top=34.481, expert1_balance_bottom=19.576, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.77, wps=88.9, ups=0.23, wpb=385.2, bsz=32, num_updates=640, lr=2.00816e-06, gnorm=3.757, loss_scale=32, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2706
2022-05-16 21:14:50 - progress_bar.py[line:272] - INFO: epoch 001:    652 / 17711 loss=3.921, loss_v1=0, loss_v2=0, nll_loss=1.897, ntokens=385.3, nsentences=32, sample_size=385.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.883491, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.086, expert1_balance_top=35.125, expert1_balance_bottom=19.431, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.72, wps=92.4, ups=0.24, wpb=385.3, bsz=32, num_updates=650, lr=2.03954e-06, gnorm=3.403, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2748
2022-05-16 21:15:33 - progress_bar.py[line:272] - INFO: epoch 001:    662 / 17711 loss=3.903, loss_v1=0, loss_v2=0, nll_loss=1.874, ntokens=391.9, nsentences=32, sample_size=391.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.88525, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=35.022, expert1_balance_bottom=19.484, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.66, wps=91.7, ups=0.23, wpb=391.9, bsz=32, num_updates=660, lr=2.07091e-06, gnorm=3.277, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2791
2022-05-16 21:16:15 - progress_bar.py[line:272] - INFO: epoch 001:    672 / 17711 loss=3.929, loss_v1=0, loss_v2=0, nll_loss=1.906, ntokens=374.1, nsentences=32, sample_size=374.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.88254, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.089, expert1_balance_top=35.317, expert1_balance_bottom=19.207, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.75, wps=87.6, ups=0.23, wpb=374.1, bsz=32, num_updates=670, lr=2.10229e-06, gnorm=3.522, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2834
2022-05-16 21:16:58 - progress_bar.py[line:272] - INFO: epoch 001:    682 / 17711 loss=3.853, loss_v1=0, loss_v2=0, nll_loss=1.815, ntokens=386.2, nsentences=32, sample_size=386.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.887086, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.091, expert1_balance_top=35.104, expert1_balance_bottom=19.293, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.52, wps=90.4, ups=0.23, wpb=386.2, bsz=32, num_updates=680, lr=2.13367e-06, gnorm=3.543, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2876
2022-05-16 21:17:41 - progress_bar.py[line:272] - INFO: epoch 001:    692 / 17711 loss=3.933, loss_v1=0, loss_v2=0, nll_loss=1.908, ntokens=384.2, nsentences=32, sample_size=384.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.885089, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=34.651, expert1_balance_bottom=19.578, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.75, wps=89.9, ups=0.23, wpb=384.2, bsz=32, num_updates=690, lr=2.16505e-06, gnorm=3.489, loss_scale=32, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2919
2022-05-16 21:18:23 - progress_bar.py[line:272] - INFO: epoch 001:    702 / 17711 loss=3.996, loss_v1=0, loss_v2=0, nll_loss=1.977, ntokens=393.1, nsentences=32, sample_size=393.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.884531, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=35.039, expert1_balance_bottom=19.383, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.94, wps=92.5, ups=0.24, wpb=393.1, bsz=32, num_updates=700, lr=2.19642e-06, gnorm=3.37, loss_scale=32, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=2962
2022-05-16 21:18:27 - trainer.py[line:945] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-05-16 21:19:10 - progress_bar.py[line:272] - INFO: epoch 001:    713 / 17711 loss=3.928, loss_v1=0, loss_v2=0, nll_loss=1.91, ntokens=385.2, nsentences=32, sample_size=385.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.875524, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.082, expert1_balance_top=35.674, expert1_balance_bottom=19.109, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.76, wps=82.1, ups=0.21, wpb=385.2, bsz=32, num_updates=710, lr=2.2278e-06, gnorm=3.646, loss_scale=16, train_wall=23, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3009
2022-05-16 21:19:52 - progress_bar.py[line:272] - INFO: epoch 001:    723 / 17711 loss=3.969, loss_v1=0, loss_v2=0, nll_loss=1.94, ntokens=390.5, nsentences=32, sample_size=390.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.888356, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.089, expert1_balance_top=34.89, expert1_balance_bottom=19.41, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.84, wps=92.8, ups=0.24, wpb=390.5, bsz=32, num_updates=720, lr=2.25918e-06, gnorm=3.491, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3051
2022-05-16 21:20:35 - progress_bar.py[line:272] - INFO: epoch 001:    733 / 17711 loss=3.864, loss_v1=0, loss_v2=0, nll_loss=1.843, ntokens=383.1, nsentences=32, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.873525, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.081, expert1_balance_top=35.607, expert1_balance_bottom=19.333, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.59, wps=89.3, ups=0.23, wpb=383.1, bsz=32, num_updates=730, lr=2.29056e-06, gnorm=3.803, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3094
2022-05-16 21:21:19 - progress_bar.py[line:272] - INFO: epoch 001:    743 / 17711 loss=4.016, loss_v1=0, loss_v2=0, nll_loss=2.02, ntokens=384, nsentences=32, sample_size=384, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.863237, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.076, expert1_balance_top=36.289, expert1_balance_bottom=18.913, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=4.05, wps=87.6, ups=0.23, wpb=384, bsz=32, num_updates=740, lr=2.32193e-06, gnorm=3.762, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3137
2022-05-16 21:22:02 - progress_bar.py[line:272] - INFO: epoch 001:    753 / 17711 loss=3.827, loss_v1=0, loss_v2=0, nll_loss=1.781, ntokens=386.4, nsentences=32, sample_size=386.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889225, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.093, expert1_balance_top=34.367, expert1_balance_bottom=19.559, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.44, wps=90.4, ups=0.23, wpb=386.4, bsz=32, num_updates=750, lr=2.35331e-06, gnorm=3.445, loss_scale=16, train_wall=20, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3180
2022-05-16 21:22:45 - progress_bar.py[line:272] - INFO: epoch 001:    763 / 17711 loss=3.938, loss_v1=0, loss_v2=0, nll_loss=1.909, ntokens=381.4, nsentences=32, sample_size=381.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.884338, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=34.68, expert1_balance_bottom=19.44, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.76, wps=89.1, ups=0.23, wpb=381.4, bsz=32, num_updates=760, lr=2.38469e-06, gnorm=3.673, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3223
2022-05-16 21:23:27 - progress_bar.py[line:272] - INFO: epoch 001:    773 / 17711 loss=3.92, loss_v1=0, loss_v2=0, nll_loss=1.887, ntokens=380.4, nsentences=32, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.887529, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.091, expert1_balance_top=34.319, expert1_balance_bottom=19.472, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.7, wps=89.1, ups=0.23, wpb=380.4, bsz=32, num_updates=770, lr=2.41607e-06, gnorm=3.44, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3266
2022-05-16 21:24:08 - progress_bar.py[line:272] - INFO: epoch 001:    783 / 17711 loss=3.957, loss_v1=0, loss_v2=0, nll_loss=1.93, ntokens=379.7, nsentences=32, sample_size=379.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.885199, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.089, expert1_balance_top=34.621, expert1_balance_bottom=19.577, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.81, wps=92.3, ups=0.24, wpb=379.7, bsz=32, num_updates=780, lr=2.44744e-06, gnorm=3.56, loss_scale=16, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3307
2022-05-16 21:24:51 - progress_bar.py[line:272] - INFO: epoch 001:    793 / 17711 loss=3.929, loss_v1=0, loss_v2=0, nll_loss=1.913, ntokens=387.4, nsentences=32, sample_size=387.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.871741, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.077, expert1_balance_top=35.422, expert1_balance_bottom=19.412, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.77, wps=90.7, ups=0.23, wpb=387.4, bsz=32, num_updates=790, lr=2.47882e-06, gnorm=3.266, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3349
2022-05-16 21:25:34 - progress_bar.py[line:272] - INFO: epoch 001:    803 / 17711 loss=3.958, loss_v1=0, loss_v2=0, nll_loss=1.935, ntokens=378.2, nsentences=32, sample_size=378.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.883028, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=35.003, expert1_balance_bottom=19.296, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.82, wps=89.1, ups=0.24, wpb=378.2, bsz=32, num_updates=800, lr=2.5102e-06, gnorm=3.243, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3392
2022-05-16 21:26:16 - progress_bar.py[line:272] - INFO: epoch 001:    813 / 17711 loss=3.969, loss_v1=0, loss_v2=0, nll_loss=1.944, ntokens=390.1, nsentences=32, sample_size=390.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.88576, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.089, expert1_balance_top=34.727, expert1_balance_bottom=19.497, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.85, wps=92.5, ups=0.24, wpb=390.1, bsz=32, num_updates=810, lr=2.54158e-06, gnorm=3.204, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3434
2022-05-16 21:26:59 - progress_bar.py[line:272] - INFO: epoch 001:    823 / 17711 loss=3.903, loss_v1=0, loss_v2=0, nll_loss=1.876, ntokens=388.2, nsentences=32, sample_size=388.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.881257, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.086, expert1_balance_top=34.819, expert1_balance_bottom=19.441, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.67, wps=90, ups=0.23, wpb=388.2, bsz=32, num_updates=820, lr=2.57295e-06, gnorm=3.296, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3477
2022-05-16 21:27:41 - progress_bar.py[line:272] - INFO: epoch 001:    833 / 17711 loss=3.843, loss_v1=0, loss_v2=0, nll_loss=1.797, ntokens=388.7, nsentences=32, sample_size=388.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.890815, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.093, expert1_balance_top=34.657, expert1_balance_bottom=19.456, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.47, wps=91.1, ups=0.23, wpb=388.7, bsz=32, num_updates=830, lr=2.60433e-06, gnorm=3.382, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3520
2022-05-16 21:28:25 - progress_bar.py[line:272] - INFO: epoch 001:    843 / 17711 loss=3.845, loss_v1=0, loss_v2=0, nll_loss=1.809, ntokens=383.1, nsentences=32, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.881595, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=35.043, expert1_balance_bottom=19.314, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.5, wps=88.1, ups=0.23, wpb=383.1, bsz=32, num_updates=840, lr=2.63571e-06, gnorm=3.237, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3563
2022-05-16 21:29:07 - progress_bar.py[line:272] - INFO: epoch 001:    853 / 17711 loss=3.93, loss_v1=0, loss_v2=0, nll_loss=1.924, ntokens=393.7, nsentences=32, sample_size=393.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.863429, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.073, expert1_balance_top=36.179, expert1_balance_bottom=19.05, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.79, wps=93, ups=0.24, wpb=393.7, bsz=32, num_updates=850, lr=2.66709e-06, gnorm=3.399, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3606
2022-05-16 21:29:49 - progress_bar.py[line:272] - INFO: epoch 001:    863 / 17711 loss=3.841, loss_v1=0, loss_v2=0, nll_loss=1.798, ntokens=381.5, nsentences=32, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.886607, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=34.69, expert1_balance_bottom=19.574, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.48, wps=90.7, ups=0.24, wpb=381.5, bsz=32, num_updates=860, lr=2.69846e-06, gnorm=4.254, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3648
2022-05-16 21:30:33 - progress_bar.py[line:272] - INFO: epoch 001:    873 / 17711 loss=3.933, loss_v1=0, loss_v2=0, nll_loss=1.904, ntokens=381.6, nsentences=32, sample_size=381.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.880633, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.086, expert1_balance_top=35.11, expert1_balance_bottom=19.448, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.74, wps=87.9, ups=0.23, wpb=381.6, bsz=32, num_updates=870, lr=2.72984e-06, gnorm=3.391, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3691
2022-05-16 21:31:16 - progress_bar.py[line:272] - INFO: epoch 001:    883 / 17711 loss=3.949, loss_v1=0, loss_v2=0, nll_loss=1.918, ntokens=382.7, nsentences=32, sample_size=382.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.886899, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.091, expert1_balance_top=34.6, expert1_balance_bottom=19.56, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.78, wps=89.3, ups=0.23, wpb=382.7, bsz=32, num_updates=880, lr=2.76122e-06, gnorm=3.316, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3734
2022-05-16 21:32:00 - progress_bar.py[line:272] - INFO: epoch 001:    893 / 17711 loss=3.948, loss_v1=0, loss_v2=0, nll_loss=1.93, ntokens=390.1, nsentences=32, sample_size=390.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.875183, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.082, expert1_balance_top=35.036, expert1_balance_bottom=19.387, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.81, wps=88, ups=0.23, wpb=390.1, bsz=32, num_updates=890, lr=2.79259e-06, gnorm=3.857, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3778
2022-05-16 21:32:42 - progress_bar.py[line:272] - INFO: epoch 001:    903 / 17711 loss=3.878, loss_v1=0, loss_v2=0, nll_loss=1.837, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.891349, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.094, expert1_balance_top=34.259, expert1_balance_bottom=19.619, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.57, wps=91.3, ups=0.24, wpb=382, bsz=32, num_updates=900, lr=2.82397e-06, gnorm=3.51, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3820
2022-05-16 21:33:25 - progress_bar.py[line:272] - INFO: epoch 001:    913 / 17711 loss=3.985, loss_v1=0, loss_v2=0, nll_loss=1.968, ntokens=388.5, nsentences=32, sample_size=388.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.877764, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.084, expert1_balance_top=34.409, expert1_balance_bottom=19.531, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.91, wps=89.1, ups=0.23, wpb=388.5, bsz=32, num_updates=910, lr=2.85535e-06, gnorm=3.615, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3864
2022-05-16 21:34:08 - progress_bar.py[line:272] - INFO: epoch 001:    923 / 17711 loss=3.894, loss_v1=0, loss_v2=0, nll_loss=1.85, ntokens=376.2, nsentences=32, sample_size=376.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.891767, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.09, expert1_balance_top=34.57, expert1_balance_bottom=19.303, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.61, wps=88.3, ups=0.23, wpb=376.2, bsz=32, num_updates=920, lr=2.88673e-06, gnorm=3.479, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3906
2022-05-16 21:34:51 - progress_bar.py[line:272] - INFO: epoch 001:    933 / 17711 loss=3.899, loss_v1=0, loss_v2=0, nll_loss=1.866, ntokens=378.8, nsentences=32, sample_size=378.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.883478, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=34.631, expert1_balance_bottom=19.412, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.65, wps=87.4, ups=0.23, wpb=378.8, bsz=32, num_updates=930, lr=2.9181e-06, gnorm=3.572, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3950
2022-05-16 21:35:35 - progress_bar.py[line:272] - INFO: epoch 001:    943 / 17711 loss=3.848, loss_v1=0, loss_v2=0, nll_loss=1.801, ntokens=377.5, nsentences=32, sample_size=377.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889003, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.093, expert1_balance_top=34.326, expert1_balance_bottom=19.423, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.48, wps=86.7, ups=0.23, wpb=377.5, bsz=32, num_updates=940, lr=2.94948e-06, gnorm=3.404, loss_scale=16, train_wall=22, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=3993
2022-05-16 21:36:17 - progress_bar.py[line:272] - INFO: epoch 001:    953 / 17711 loss=3.941, loss_v1=0, loss_v2=0, nll_loss=1.908, ntokens=377.3, nsentences=32, sample_size=377.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.88625, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.088, expert1_balance_top=34.64, expert1_balance_bottom=19.497, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.75, wps=88.6, ups=0.23, wpb=377.3, bsz=32, num_updates=950, lr=2.98086e-06, gnorm=3.345, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4036
2022-05-16 21:37:00 - progress_bar.py[line:272] - INFO: epoch 001:    963 / 17711 loss=3.92, loss_v1=0, loss_v2=0, nll_loss=1.895, ntokens=386.8, nsentences=32, sample_size=386.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.877783, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.085, expert1_balance_top=34.846, expert1_balance_bottom=19.355, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.72, wps=91.9, ups=0.24, wpb=386.8, bsz=32, num_updates=960, lr=3.01224e-06, gnorm=3.614, loss_scale=16, train_wall=20, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4078
2022-05-16 21:37:43 - progress_bar.py[line:272] - INFO: epoch 001:    973 / 17711 loss=3.832, loss_v1=0, loss_v2=0, nll_loss=1.8, ntokens=397.1, nsentences=32, sample_size=397.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.873456, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.083, expert1_balance_top=35.066, expert1_balance_bottom=19.437, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.48, wps=92.1, ups=0.23, wpb=397.1, bsz=32, num_updates=970, lr=3.04361e-06, gnorm=3.336, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4121
2022-05-16 21:38:25 - progress_bar.py[line:272] - INFO: epoch 001:    983 / 17711 loss=3.857, loss_v1=0, loss_v2=0, nll_loss=1.808, ntokens=382.9, nsentences=32, sample_size=382.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.891084, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.093, expert1_balance_top=34.114, expert1_balance_bottom=19.526, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.5, wps=89.8, ups=0.23, wpb=382.9, bsz=32, num_updates=980, lr=3.07499e-06, gnorm=3.459, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4164
2022-05-16 21:39:07 - progress_bar.py[line:272] - INFO: epoch 001:    993 / 17711 loss=3.876, loss_v1=0, loss_v2=0, nll_loss=1.84, ntokens=385.1, nsentences=32, sample_size=385.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.881147, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.085, expert1_balance_top=34.927, expert1_balance_bottom=19.335, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.58, wps=91.3, ups=0.24, wpb=385.1, bsz=32, num_updates=990, lr=3.10637e-06, gnorm=3.206, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4206
2022-05-16 21:39:50 - progress_bar.py[line:272] - INFO: epoch 001:   1003 / 17711 loss=3.913, loss_v1=0, loss_v2=0, nll_loss=1.875, ntokens=379.8, nsentences=32, sample_size=379.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.88487, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=34.587, expert1_balance_bottom=19.496, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.67, wps=88.2, ups=0.23, wpb=379.8, bsz=32, num_updates=1000, lr=3.13775e-06, gnorm=3.093, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4249
2022-05-16 21:40:33 - progress_bar.py[line:272] - INFO: epoch 001:   1013 / 17711 loss=3.902, loss_v1=0, loss_v2=0, nll_loss=1.86, ntokens=378.6, nsentences=32, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.89074, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.092, expert1_balance_top=34.325, expert1_balance_bottom=19.575, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.63, wps=88.7, ups=0.23, wpb=378.6, bsz=32, num_updates=1010, lr=3.16912e-06, gnorm=3.485, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4292
2022-05-16 21:41:17 - progress_bar.py[line:272] - INFO: epoch 001:   1023 / 17711 loss=3.929, loss_v1=0, loss_v2=0, nll_loss=1.877, ntokens=373.4, nsentences=32, sample_size=373.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.900433, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.097, expert1_balance_top=33.527, expert1_balance_bottom=19.751, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.67, wps=85.7, ups=0.23, wpb=373.4, bsz=32, num_updates=1020, lr=3.2005e-06, gnorm=3.493, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4335
2022-05-16 21:42:00 - progress_bar.py[line:272] - INFO: epoch 001:   1033 / 17711 loss=3.876, loss_v1=0, loss_v2=0, nll_loss=1.833, ntokens=380, nsentences=32, sample_size=380, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.888795, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.091, expert1_balance_top=34.161, expert1_balance_bottom=19.714, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.56, wps=88.1, ups=0.23, wpb=380, bsz=32, num_updates=1030, lr=3.23188e-06, gnorm=3.395, loss_scale=16, train_wall=20, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4378
2022-05-16 21:42:42 - progress_bar.py[line:272] - INFO: epoch 001:   1043 / 17711 loss=3.886, loss_v1=0, loss_v2=0, nll_loss=1.85, ntokens=375.9, nsentences=32, sample_size=375.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.884862, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.087, expert1_balance_top=34.891, expert1_balance_bottom=19.414, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.61, wps=88.3, ups=0.23, wpb=375.9, bsz=32, num_updates=1040, lr=3.26326e-06, gnorm=4.116, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4421
2022-05-16 21:43:25 - progress_bar.py[line:272] - INFO: epoch 001:   1053 / 17711 loss=3.935, loss_v1=0, loss_v2=0, nll_loss=1.895, ntokens=385.2, nsentences=32, sample_size=385.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss=0.889471, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.093, expert1_balance_top=34.02, expert1_balance_bottom=19.64, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=3.72, wps=90.6, ups=0.24, wpb=385.2, bsz=32, num_updates=1050, lr=3.29463e-06, gnorm=3.669, loss_scale=16, train_wall=21, cuda_gb_allocated=14.8, cuda_gb_reserved=15.7, cuda_gb_free=8.9, wall=4463
Killing subprocess 43887
Main process received SIGINT, exiting
